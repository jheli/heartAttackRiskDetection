{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"model_input_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>sex_binari</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Blood_Pressure_low</th>\n",
       "      <th>Blood_Pressure_high</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>...</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>Exercise Hours Per Week</th>\n",
       "      <th>diet_int</th>\n",
       "      <th>Previous Heart Problems</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Heart Attack Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>88</td>\n",
       "      <td>158</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.168189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31.251233</td>\n",
       "      <td>286</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>93</td>\n",
       "      <td>165</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813242</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.194973</td>\n",
       "      <td>235</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>99</td>\n",
       "      <td>174</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>28.176571</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.828130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>36.464704</td>\n",
       "      <td>378</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.804299</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>21.809144</td>\n",
       "      <td>231</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>8758</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>76</td>\n",
       "      <td>94</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.917342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>19.655895</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>8759</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>102</td>\n",
       "      <td>157</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16.558426</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>23.993866</td>\n",
       "      <td>617</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>8760</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.148438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>35.406146</td>\n",
       "      <td>527</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>8761</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>119</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789950</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27.294020</td>\n",
       "      <td>114</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>8762</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>67</td>\n",
       "      <td>138</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.081748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>32.914151</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8763 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Age  sex_binari  Cholesterol  Blood_Pressure_low  \\\n",
       "0              0   67           0          208                  88   \n",
       "1              1   21           0          389                  93   \n",
       "2              2   21           1          324                  99   \n",
       "3              3   84           0          383                 100   \n",
       "4              4   66           0          318                  88   \n",
       "...          ...  ...         ...          ...                 ...   \n",
       "8758        8758   60           0          121                  76   \n",
       "8759        8759   28           1          120                 102   \n",
       "8760        8760   47           0          250                  75   \n",
       "8761        8761   36           0          178                  67   \n",
       "8762        8762   25           1          356                  67   \n",
       "\n",
       "      Blood_Pressure_high  Heart Rate  Diabetes  Family History  Smoking  ...  \\\n",
       "0                     158          72         0               0        1  ...   \n",
       "1                     165          98         1               1        1  ...   \n",
       "2                     174          72         1               0        0  ...   \n",
       "3                     163          73         1               1        1  ...   \n",
       "4                      91          93         1               1        1  ...   \n",
       "...                   ...         ...       ...             ...      ...  ...   \n",
       "8758                   94          61         1               1        1  ...   \n",
       "8759                  157          73         1               0        0  ...   \n",
       "8760                  161         105         0               1        1  ...   \n",
       "8761                  119          60         1               0        1  ...   \n",
       "8762                  138          75         1               1        0  ...   \n",
       "\n",
       "      Alcohol Consumption  Exercise Hours Per Week  diet_int  \\\n",
       "0                       0                 4.168189         0   \n",
       "1                       1                 1.813242        -1   \n",
       "2                       0                 2.078353         1   \n",
       "3                       1                 9.828130         0   \n",
       "4                       0                 5.804299        -1   \n",
       "...                   ...                      ...       ...   \n",
       "8758                    1                 7.917342         1   \n",
       "8759                    0                16.558426         1   \n",
       "8760                    1                 3.148438         0   \n",
       "8761                    0                 3.789950        -1   \n",
       "8762                    1                18.081748         1   \n",
       "\n",
       "      Previous Heart Problems  Medication Use  Stress Level        BMI  \\\n",
       "0                           0               0             9  31.251233   \n",
       "1                           1               0             1  27.194973   \n",
       "2                           1               1             9  28.176571   \n",
       "3                           1               0             9  36.464704   \n",
       "4                           1               0             6  21.809144   \n",
       "...                       ...             ...           ...        ...   \n",
       "8758                        1               1             8  19.655895   \n",
       "8759                        0               0             8  23.993866   \n",
       "8760                        1               0             5  35.406146   \n",
       "8761                        1               1             5  27.294020   \n",
       "8762                        0               0             8  32.914151   \n",
       "\n",
       "      Triglycerides  Sleep Hours Per Day  Heart Attack Risk  \n",
       "0               286                    6                  0  \n",
       "1               235                    7                  0  \n",
       "2               587                    4                  0  \n",
       "3               378                    4                  0  \n",
       "4               231                    5                  0  \n",
       "...             ...                  ...                ...  \n",
       "8758             67                    7                  0  \n",
       "8759            617                    9                  0  \n",
       "8760            527                    4                  1  \n",
       "8761            114                    8                  0  \n",
       "8762            180                    4                  1  \n",
       "\n",
       "[8763 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating dataset class\n",
    "##########################\n",
    "\n",
    "class HeartAttackRiskData(Dataset):\n",
    "    def __init__(self, inputs, outputs) -> None:\n",
    "        super().__init__()\n",
    "        self.n = len(inputs)\n",
    "        self.i = 0\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "    \n",
    "    def __getitem__(self, index) -> any:\n",
    "        input = self.inputs[self.i]\n",
    "        output = self.outputs[self.i]\n",
    "        #input = df.loc[self.i][1:-1]\n",
    "        #output = df.loc[self.i][-1]\n",
    "        #input_tensor = torch.tensor(np.array(input))\n",
    "        #output_tensor = torch.tensor(np.array([output]))\n",
    "        self.i = self.i+1\n",
    "        if self.i == self.n:\n",
    "            self.i = 0\n",
    "        return torch.tensor(np.array(input)), torch.tensor(np.array([output]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spliting data in training and testing. Making loader objects for easyly feed the model\n",
    "##########################################################################################\n",
    "\n",
    "# shuffling the data\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "# making the training and testing dataset from all available data\n",
    "train_df_index = int(0.8*len(df))\n",
    "df_train = df.iloc[0:train_df_index]\n",
    "df_test = df.iloc[train_df_index:len(df)]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "inputs_train = torch.tensor(np.array([df_train.iloc[i].iloc[1:-1] for i in range(len(df_train))])).type(torch.FloatTensor)\n",
    "outputs_train = torch.tensor(np.array([df_train.iloc[i].iloc[-1] for i in range(len(df_train))])).type(torch.FloatTensor)\n",
    "inputs_test = torch.tensor(np.array([df_test.iloc[i].iloc[1:-1] for i in range(len(df_test))])).type(torch.FloatTensor)\n",
    "outputs_test = torch.tensor(np.array([df_test.iloc[i].iloc[-1] for i in range(len(df_test))])).type(torch.FloatTensor)\n",
    "#outputs_train = [torch.tensor(np.array(df_train.iloc[i].iloc[-1])).type(torch.FloatTensor) for i in range(len(df_train))]\n",
    "#inputs_test = [torch.tensor(np.array(df_test.iloc[i].iloc[1:-1])).type(torch.FloatTensor) for i in range(len(df_test))]\n",
    "#outputs_test = [torch.tensor(np.array(df_test.iloc[i].iloc[-1])).type(torch.FloatTensor) for i in range(len(df_test))]\n",
    "train_data = HeartAttackRiskData(inputs_train, outputs_train)\n",
    "test_data = HeartAttackRiskData(inputs_test, outputs_test)\n",
    "\n",
    "# making data loader objects\n",
    "train_loader = DataLoader(train_data, batch_size=64)\n",
    "test_loader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49.0000,   0.0000, 166.0000,  ...,  25.4143, 593.0000,   8.0000],\n",
      "        [ 26.0000,   0.0000, 382.0000,  ...,  39.9201, 223.0000,   6.0000],\n",
      "        [ 29.0000,   0.0000, 362.0000,  ...,  38.3953, 469.0000,   5.0000],\n",
      "        ...,\n",
      "        [ 40.0000,   1.0000, 334.0000,  ...,  35.1328, 380.0000,  10.0000],\n",
      "        [ 56.0000,   0.0000, 189.0000,  ...,  24.2746, 140.0000,   4.0000],\n",
      "        [ 89.0000,   0.0000, 392.0000,  ...,  38.5656, 197.0000,   4.0000]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "for input, output in train_loader:\n",
    "    print(input)\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model definition\n",
    "####################\n",
    "\n",
    "# Model feeded with a logaritmic filtered spectogram of an audio sample\n",
    "# Combination of 5x5 convolutional and 2x2 MaxPool layers with two final linear layers. \n",
    "# ReLU activation function after each layer with the exeption of a final sigmoid (0 -> minor, 1 -> major)\n",
    "\n",
    "class HeartAttackRiskDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(19, 64)\n",
    "        self.layer2 = nn.Linear(64,64)\n",
    "        self.layer3 = nn.Linear(64,1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        #print(\"model output:\", x)\n",
    "        #x = self.layer3(x)\n",
    "        #print(x)\n",
    "        #print(self.sig(x))\n",
    "        return nn.functional.sigmoid(x)\n",
    "    \n",
    "#def init_weights(m):\n",
    "#    if type(m) == nn.Linear:\n",
    "#        m.weight.fill_(1)\n",
    "\n",
    "# model\n",
    "net = HeartAttackRiskDetectionModel()\n",
    "#net.apply(init_weights)\n",
    "# optimizer\n",
    "opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "# loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# losses history\n",
    "losses = []\n",
    "# accuracy history\n",
    "accuracies = []\n",
    "best_accuracy = 0\n",
    "# epoch counter\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "#####################\n",
    "\n",
    "### poner bien las dimensiones de output y predictions para que funcione bien la funcion loss\n",
    "\n",
    "def training(numberOfEpochs):\n",
    "    global epoch\n",
    "    global best_accuracy\n",
    "    for i in range(numberOfEpochs):\n",
    "        epoch += 1\n",
    "        total_correct = 0\n",
    "        total = train_data.__len__()\n",
    "        for input, output in train_loader:\n",
    "            # feeding the model\n",
    "            #print(\"len input = \",input.size())\n",
    "            #print(\"len output = \",output.size())\n",
    "            #input = input.type(torch.FloatTensor)\n",
    "            #output = output.type(torch.FloatTensor)\n",
    "            predictions = net(input)\n",
    "            #predictions_acc = outputs[1]\n",
    "            #predictions = predictions.type(torch.DoubleTensor)\n",
    "            #predictions_flatten = torch.flatten(predictions_double)\n",
    "            #predictions_acc_double = predictions_acc.type(torch.DoubleTensor)\n",
    "            #predictions_acc_flatten = torch.flatten(predictions_acc_double)\n",
    "            #print(\"len predictions = \",output.size())\n",
    "            # training\n",
    "            #output = torch.tensor(output)\n",
    "            #print(input)\n",
    "            #print(output)\n",
    "            #print(predictions)\n",
    "            loss = loss_fn(output, predictions)\n",
    "            #loss = sum((output-predictions)*(output-predictions))\n",
    "            #print(loss)\n",
    "            losses.append(loss)\n",
    "            #opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            # computing accuracy\n",
    "            #total_correct = sum(nn.Sigmoid(predictions).round() == output)\n",
    "            #print(\"pred-output: \",predictions-output)\n",
    "            #print(\"pred-output <= 0.5: \",predictions-output <= 0.5)\n",
    "            total_correct += sum((torch.abs(predictions-output) <= 0.5))\n",
    "            #print(total_correct)\n",
    "        # saving and printing accuracy of this epoch\n",
    "        accuracy = total_correct / total\n",
    "        accuracies.append(accuracy.item())\n",
    "        print(epoch, total_correct/total)\n",
    "        # saving the model if it is the best one or if it has > 0.90 accuracy\n",
    "        if accuracy > 0.9:\n",
    "            torch.save(net, f'./models/epoch{epoch}.pkl')\n",
    "        if accuracy > best_accuracy:\n",
    "            torch.save(net, f'./models/best.pkl')\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([0.6411])\n",
      "2 tensor([0.6357])\n",
      "3 tensor([0.6409])\n",
      "4 tensor([0.6375])\n",
      "5 tensor([0.5974])\n",
      "6 tensor([0.6049])\n",
      "7 tensor([0.6187])\n",
      "8 tensor([0.6218])\n",
      "9 tensor([0.6284])\n",
      "10 tensor([0.6341])\n",
      "11 tensor([0.6362])\n",
      "12 tensor([0.6375])\n",
      "13 tensor([0.6377])\n",
      "14 tensor([0.6392])\n",
      "15 tensor([0.6391])\n",
      "16 tensor([0.6397])\n",
      "17 tensor([0.6405])\n",
      "18 tensor([0.6384])\n",
      "19 tensor([0.6367])\n",
      "20 tensor([0.6379])\n",
      "21 tensor([0.6398])\n",
      "22 tensor([0.6378])\n",
      "23 tensor([0.6384])\n",
      "24 tensor([0.6398])\n",
      "25 tensor([0.6402])\n",
      "26 tensor([0.6404])\n",
      "27 tensor([0.6407])\n",
      "28 tensor([0.6398])\n",
      "29 tensor([0.6427])\n",
      "30 tensor([0.6419])\n",
      "31 tensor([0.6414])\n",
      "32 tensor([0.6422])\n",
      "33 tensor([0.6428])\n",
      "34 tensor([0.6439])\n",
      "35 tensor([0.6441])\n",
      "36 tensor([0.6435])\n",
      "37 tensor([0.6439])\n",
      "38 tensor([0.6434])\n",
      "39 tensor([0.6469])\n",
      "40 tensor([0.6462])\n",
      "41 tensor([0.6474])\n",
      "42 tensor([0.6458])\n",
      "43 tensor([0.6432])\n",
      "44 tensor([0.6461])\n",
      "45 tensor([0.6466])\n",
      "46 tensor([0.6479])\n",
      "47 tensor([0.6481])\n",
      "48 tensor([0.6502])\n",
      "49 tensor([0.6495])\n",
      "50 tensor([0.6486])\n",
      "51 tensor([0.6506])\n",
      "52 tensor([0.6501])\n",
      "53 tensor([0.6506])\n",
      "54 tensor([0.6511])\n",
      "55 tensor([0.6494])\n",
      "56 tensor([0.6524])\n",
      "57 tensor([0.6525])\n",
      "58 tensor([0.6559])\n",
      "59 tensor([0.6522])\n",
      "60 tensor([0.6532])\n",
      "61 tensor([0.6515])\n",
      "62 tensor([0.6526])\n",
      "63 tensor([0.6532])\n",
      "64 tensor([0.6529])\n",
      "65 tensor([0.6535])\n",
      "66 tensor([0.6555])\n",
      "67 tensor([0.6552])\n",
      "68 tensor([0.6546])\n",
      "69 tensor([0.6539])\n",
      "70 tensor([0.6548])\n",
      "71 tensor([0.6546])\n",
      "72 tensor([0.6553])\n",
      "73 tensor([0.6572])\n",
      "74 tensor([0.6563])\n",
      "75 tensor([0.6546])\n",
      "76 tensor([0.6599])\n",
      "77 tensor([0.6596])\n",
      "78 tensor([0.6575])\n",
      "79 tensor([0.6562])\n",
      "80 tensor([0.6602])\n",
      "81 tensor([0.6626])\n",
      "82 tensor([0.6595])\n",
      "83 tensor([0.6611])\n",
      "84 tensor([0.6611])\n",
      "85 tensor([0.6638])\n",
      "86 tensor([0.6621])\n",
      "87 tensor([0.6616])\n",
      "88 tensor([0.6619])\n",
      "89 tensor([0.6641])\n",
      "90 tensor([0.6652])\n",
      "91 tensor([0.6643])\n",
      "92 tensor([0.6649])\n",
      "93 tensor([0.6658])\n",
      "94 tensor([0.6659])\n",
      "95 tensor([0.6680])\n",
      "96 tensor([0.6648])\n",
      "97 tensor([0.6682])\n",
      "98 tensor([0.6685])\n",
      "99 tensor([0.6656])\n",
      "100 tensor([0.6680])\n"
     ]
    }
   ],
   "source": [
    "# This cell has been run several times for training the model\n",
    "\n",
    "training(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.6792e-06, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2442, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4974, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.1033, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2609, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5006, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.1518e-22, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5127, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5001, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4829, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.6816e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4960, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1763e-05, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.2267e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3707e-08, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2938e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7498, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.7498e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2496, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.0050e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.0121e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0841e-14, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.3464e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.0213e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.3699e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2491, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4999, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.1365e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4993, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2757e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.6821e-15, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.7083e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.5909e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.0527e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1188e-14, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.2202e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.8939e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4997, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7940e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.7805e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7496, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4992, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4995, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1209e-05, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.0998e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4999, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4998, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7249, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2916, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5627, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7495, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.6634, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5045, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.6387, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4363, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.3725, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.9492e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.6918, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2211, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4986, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2593e-07, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2398, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.1876, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.0684, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2503, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.2243e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2872e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4999, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2502, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.0001, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4635, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.8981e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1021e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.1906, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8900e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2501, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2512, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.6267e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4988, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4160, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2508, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.1822, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4877, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.0279, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.0001, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4645e-14, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.1475e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.4090e-15, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.7937e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.7243e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.4339e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1866e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.7200e-17, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0313e-34, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(4.7278e-19, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6655e-22, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.2112e-38, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.3965e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.5675e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.4000e-28, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.1764e-19, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.4360e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1544e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2009e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.7206e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3305e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4070e-29, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.3211e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0318e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.3914e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1824e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1956e-25, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.1659e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.6675e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4101e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.0484e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.3727e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.6809e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.3417e-32, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6937e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.5095e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.7633e-33, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.0718e-31, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.6334e-17, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3874e-19, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4996, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.4720e-08, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.9123e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.2452e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.3793e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4999, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.6520e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5003, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.5409e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2499, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.9545e-27, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7603e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.2623e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6597e-07, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7496, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7250e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.6706e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2736e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5001, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2493, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.6562, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.4276e-05, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5009, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1359e-14, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.9963e-10, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7495, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4941, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7090, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.1438e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7497, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.8594e-06, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.3745, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.3928, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7468, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4998, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.9213e-09, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2520, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.0732, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4973, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2344, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.3921e-28, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.7105e-27, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.7934e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4882, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7499, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4999, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4997, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7414, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.5085e-07, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5011, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5954, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.7428e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7938e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(8.2305e-29, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(6.9935e-38, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3886e-32, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1272e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6427e-37, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4416e-33, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.3346e-22, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2788e-36, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(2.3182e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.1054e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4105e-17, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.9789e-27, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3132e-31, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.5807e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.2789e-29, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.2202e-37, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.8137e-31, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.5509e-14, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.0466e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.2969e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8368e-41, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.0753e-42, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6788e-42, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0855e-29, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.1943e-34, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.2623e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.5864e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.5531e-32, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.7412e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0230e-32, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.0836e-17, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.8230e-33, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.6111e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.9665e-39, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.3822e-44, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.4027e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.8906e-39, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7558e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.9251e-35, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.9589e-28, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.3686e-24, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.0974e-19, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.6082e-15, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0754e-17, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0311e-12, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(7.6414e-22, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.6818e-20, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.1210e-44, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.5396e-32, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.1894e-27, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.4979e-31, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(2.3120e-15, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7117e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.7783e-26, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.2744e-31, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.0542e-30, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.2822e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.4013e-45, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.2557e-34, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.0946e-22, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.8605e-21, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.3992e-13, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8350e-40, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(9.2752e-42, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.5703e-16, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.9108e-40, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.4485e-33, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.6765e-39, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.3140e-23, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.2230e-43, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.8579e-18, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(4.6279e-11, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0., grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1147e-34, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.7500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(5.4578e-39, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.2500, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.5000, grad_fn=<MseLossBackward0>),\n",
       " ...]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = []\n",
    "for e in losses:\n",
    "    graph.append(e.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b1c313b950>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz4klEQVR4nO3de3wU9b3/8XcSyAaEJGAkAQwNXlFBQJA0XlqtqdFy6LHtOaXKEUrVHi16wLQqVIVaL+FY5dBTUSqK9qKC9qfWCsKhkYtoIBIIckcJkIjkgkg2BEhI9vv7I2bJ5rq77Oa7m309fexDMvudme98dmb2vbMzs1HGGCMAAABLom13AAAARDbCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrutnugDdcLpe++OIL9e7dW1FRUba7AwAAvGCMUVVVlQYMGKDo6LaPf4RFGPniiy+UmppquxsAAMAPJSUlOvvss9t8PizCSO/evSU1LEx8fLzl3gAAAG84nU6lpqa638fbEhZhpPGrmfj4eMIIAABhpqNTLDiBFQAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFjlcxhZs2aNxo0bpwEDBigqKkpvv/12h+OsWrVKl112mRwOh8477zy9/PLLfnQVAAB0RT6Hkerqag0fPlzz5s3zqv3evXs1duxYXXvttSosLNS0adN0++23a/ny5T53FgAAdD0+/zbNjTfeqBtvvNHr9vPnz9fgwYP19NNPS5IuuugirV27Vv/zP/+jrKwsX2cPAAC6mKCfM5KXl6fMzEyPYVlZWcrLy2tznJqaGjmdTo9HsK0r+lJTF23SZY+u0H1vbFaZ80SLNuVVJzR/9R59ebSmxXOvrN+vW19cr72Hqj2Glxw+pj+u3qNdpVV6btUe/eadbZryykZVVNXI5TJ66cO92vJ5pSSp3mW0cO1ebT3Q8Pdbmz7X6t0VLeZ1sPK45q/eoyPHamWM0V/X7deGfYc92tTWufTCB0XaXVblHjbr71t1+58+9mhXVHFUz6/Zo2VbD+rvhQc8niv+sqHv1TV1WvxxsdYVfSlJ2l1WpRlvfqL0J/6pyS/le8yj0fHaej2/Zk+LekjS6t0V+uGzH2pj8Vcew48cq9X8r2s1f/Uezf3nbk14YZ32VBxttR7/r+BzffBpw99rdlfozY2ft5hX1YmT+uPqPSo5fEyS9N6Wg1q+rbRFu0X5p5ZPkv6St0+Zc1brZL3LPezQ0RrNX71H7+8s00sf7pXLZdzPfVXd0Pcy5wmt2F6mJZ8clCSVVp7Qo+9u13eeWqXvP7NW65vMo5ExRn/O26dNzeohSVs+r9SPnvtIK7aXeQxvfH23fVGpFz4o0gsfFOkHz36ogv2HW63Hql3lentTw+u79UClFq7dq/om/Zdarn/ri77Ua/nFLfq0YnuZlm456P57ze4KjX7snyqvOrXNnDhZrwVrirRyV7n+uHqPjtbUtej77rIqFez/Sn/J2ydjjI7W1GnuP3frhrlrdO1Tqzzm0dQ/Nn+h3B1lLYaXHD6myS/la+HavS2ea1x/X99Qohc+KNK/z/9Iy7YebLUeWz6vdL++jdtv1YmTLab55sbPtebr9fHTsiq98EGRaurqPdo0XT5J+qz8qC57dIV7m5caXv+/rNuvf24vc69DTb2WX6z1RV+6t9XjtfXufccPnv1QGTm5enHtXvc8mvpozyG9/nFJi+FHjtXq3sWFeuzd7R7ruCT3+pu7o6E/t738sRasKXLXuGk9Gv8+WlOnymMnNX/1Hh2sPN5ifqt3V+itTQ3rY5mzYT96uLrWo82eiqNasKZIJ0421LDqxEll5OS2WA/e23JQSz452GL/Jkn/t61US7ccVEVVw7ZaUdWwr3570wFNWpiv0Y+t0Oz3drrn0dTOUqde+KCoRT1q61x67N3tyl5cqMpjnutB4+u7qfgrPfP+p8p+vVC//cd21dTVt6hH4/6ttPKETtY3bAM7S1u+tzWujy6XUXVNnf64eo/2f+m5H21cvkNfvxe5XEb/+sxazVv5mUe7xm24cR3y7Pth/WXdfve22riftSXov9pbWlqq5ORkj2HJyclyOp06fvy4evTo0WKcnJwcPfLII8HumoefPL/O/e83Cj7XxuKvlPvLazza/Ozlj7X1gFPv7yjX63dmuIfvqTiqB9/aKkm69qlV2jd7rPu5G3//gY7W1CnnvZ0e0yr56pgmZqTpkX9slyTtmz1Wiz8u0W/fbfh71a+u0b2LN7ufa+rHf8xTyeHj2rDvK92a8Q099PbWFu1eWFukJ5ftkpbs0L7ZY+U8cVJ/ytsvScrfe1hjBveVJH3n6dUe075sUB+l9u0pSbp+7mqdOOnSW5sOaGdplXse1//PGnf7MmeFVu6qaNHH3y3fpYUf7tUTS3e2eG7SwnxJ0g+f/cjjuXsXF2rlrgrNblar655erZXN6vFZeZV++capvyd+Pc3hqYk696xe7nFnvbNNb248oHkrP9Pa6d/RXa9slCTtfPQGxXWPkSRt2HdY09/c4lHDh/++TZI05ZWNen7iaEnSnX8p0Ib9pwJDYs/u+sHIsyVJUxcXas3uCr2WX6z9XzYEn2+ek6lbFqxTUZNANv75dS3qsXxbqWZ+Pb/mz417Zq0k6Y4/b9DenO+5f/ly4Yd7W9RJkn70XF6r9fjpSw0hdOSgRP3LHxqmeYYjRuMvH+Qe928Fp9a/fbPHavzX28S5Z/Vyry+1dS7d8ecNkqTCmd9VYs9Y97zGPJ7r7v/vcz/Vc6v2uKe978tq5fzwUknS82v26Kn/2y0t2eF+fkBiD63YXqZFTd44f/HKRm2eeb0SenZ3DyuvOqF7XtskSR71kE5tayt3VWh0Wh9denaiJGlj8Vd64P9taVGrj/d9pZ2P3tCiHo01T+jRXb95Z5ucJ+q0q7RKc8aPcI9bVHFU2a+fWv+++/U2cby2Xvdcd36T1+MjSdLAPj30nSHJypzTsL2Ne2atu1ardlfo4a+3YUl6Y0OJe9+Tv/ewZrzp2fdDR2t1Uf/e7n2HJD367nadc9YZuvbCfh5tb1mwXpI0pH9vdz0k6Zevb1buznJJUnJ8nO741jmSpJP1p17fpnJ3lmvEoETd9vLHcp6o0+6yo3r6x8N1w9w1qq6tV1FFtQ4fq9WK7WX667r9WvvAdzzGb9zmR6T20R1/3qDPyo/qw88O6S+3pbvbXPf1vujwsVo9cMMQXfboCp2sN/rFKxvdtao8ftK9DUty798kqaauXj//S4Ek6ZyzzlBRRbXe21qqP/xkpKYtLnSPMn/1HkVHSfffMMSjjzfM/cD979uvPsf974Uf7tULXwfcozV17v2BdOr1be7MXrEqLDniUY9piwu1aleFFn9cognpg/TY1+t/822+cX3sHddNm0qO6NX1xZqzYrd2PXbqG4nb/7xBm0uO6P+2lerNX1ypubmfavPnldr8eaWmXHueu934Ju9rzef1o+caDgi8sm6/dpZW6fGlO1r0pTOF5NU0M2bMUGVlpftRUtIy2QfbnoqWn+i3HmhIsfnNjkK0dhSlUdNPhE198nmldh70TMU7mvxdXtXy6EujksMNSfuDTyu0t400+0lJpcffx2pOfRLY18rRikaHmhz1OXGy4RNCYxDxxYb9hztu1ExrR4EaVTSrR5mz9fo0b5e3p+HTgPNEnUcNapt8+in++qhJa/6vyRGJpkFEknaXnap94yfkxiAiNbz2Re3UutFn5b5/Ivnk8yNetWtej0NHT30a3XHQ83Vt/nejpvWpc52qW1vrttTwibGp9UWn1ofCZuumJBVVVHscmWpUXes5D+fxlkcoWuvPga9OfTovaef1rWtydKj58u8qq5LzRMM085r1ra3tc/PnLZdNali+tuxt9lzTfU9r62bB/q9a3SabT6eppvWQPLe1rV+c6nPzo2VNlRw+5q5H42tVXduwTa3f+6V7G/j8q5ZHRhpVVNW41/cPPj3UapvGdedkfcu+VLezzjVt31jvzSVHVNHKkezmR2Wb2vaF53656bbWVp+b21xypEU9Vu1q+HvvoWptOdD6etLUrtIq99GMmjrPozWbSxr6tLG44f9r2tl3dsSf/XswBP3ISEpKisrKPA+plpWVKT4+vtWjIpLkcDjkcDiC3TUAABACgn5kJCMjQ7m5uR7DVqxYoYyMjDbGAAAAkcTnMHL06FEVFhaqsLBQUsOlu4WFhSoubjjRbcaMGZo4caK7/Z133qmioiLdf//92rlzp5599lm9/vrruvfeewOzBAAAIKz5HEY2bNigkSNHauTIkZKk7OxsjRw5UjNnzpQkHTx40B1MJGnw4MFasmSJVqxYoeHDh+vpp5/WCy+8wGW9ADrU9hkMaI5aea+VC49gmc/njFxzzTWtXkLWqLW7q15zzTXatGmTr7MCAAARICSvpgEAAJGDMBLmvD3aaLxs2ZWPXnpbA6+n18HkQuFQcCj0Qep4vQr0a9OVtXdkOpL6EAm837+HP8JIAEQpquNGrY3n32inz9Z8T0OgaxWGJbAm0LXy5bUMtzc9m+upL7Wytu8JIp9q5dN0w2z/HqYIIwA6VZjlC6solfeoVXgjjHRR/h72DlSYD5U3HG/64W9fA/XJJ1Rq5Q2/a2V5/oEWKv0AugrCSBjz5c3Q41AjO1IEQBTHob1mu1ah8lJ50w/bXbU9/0a+7d/DH2EEAABYRRgBELL4OgRBwXoVcggjIcTX8zyM8X5n3dUunfTnTSrQb2wdXtob2NmFtQ4v7bVUrHC7Wkeyt14FYn0Pw3L7JRDruzFeTMjL+YUDwkgAhMr3sV5rp782V+pAfK/efAptTdL2d/inKxCXG9oqQWe/Jv5Ot2mNvV6v/JpTe31oa/jpzel0x28xvRDYntqs1el2zf6iRQTCSIgKx09s6JpC4H0GQBdHGAGALoDPL97ral9bdwWEEQAAYBVhBECn4hO89yiV96hVeCOMwAOnB3iPcym8R6kAtIcwAgAArCKMdFG2D4X7c4JYIK4gaj4Fr67n93deAaqx1z8T3qSht/Vt3s5jGt7ew8Bjvv7x7h4UHbfy5yfVvV2vmrdrWjt/1qtgCuQJmH7ds6fFNEL3S5JAdo0TX4OHMBIA/h6Cbn5tvsd9Dbz4DiAYXxOE6qbm7X0e0Hn8X+8D2o3T0ln3x/C7VsHqgR8T7qhU3kzSq9+m8XOhA1ar0y+VotT+vVyCWYdwRRgB0K5I2ykC6HyEEQAAYBVhBEDICuFTEUIO5zN4j/Uq9BBGAACAVYQRAABgFWEEAABYRRgJIb5+52uMf/eo6AoCcW+EYAvley8EQiCXzp9pBaK8nfUaBbRWfk0sAPfw6WAS3t1LJjBtgioQ61VHz3tZB6+7Yr1op48w0kW1dzlmZ1yp2d419m2OE4BrSL29H0lUG/+2wb/7GPjX66b18LbcHuP4NVdv59Ny6s0Durfz93h9/VyvPO770/y5ttarTlqZWnv9/X0/CkSfO+t+Lf5orWv+vnX7u92hY4QRAABgFWEkRJ3u4WPbR+1C5TLDYN4OPlBsz98Xtvtqe/6NbG9fQFdDGAljvhwZDeGjqAhTrFLes18r+z2QwuQ26Lbn/zWf6mC9aKePMBKB+FAHAAglhBEAIYuvQ7xHqbzX1a90C0eEkTDn/c+jB7kjYSDQO6COzosJiZKHRCc6rn0orJ8h0AWvhEI/Q+H1igRe77O6wAtCGAkA/y8dtKO9+YbqOh3or0S7wFesYasrlz7Ql34Gaz3tiq9B0Grl7/69KxY5iAgjANrFvRUABBthBECn8uXgW4geqOs0vhypDNWjmp3Fp1oFrxvwE2EEHji06D2OGHgvlO/QCcA+wggAALCKMAIAAKwijAAAAKsII12U7RO0wulkOn/vPxKo39/x+lYCAZmb75oup9+1CtAKEeq1CkfhtK3aFiq/udUVEUYCIBjn5gXzhL/2ps2OCd7ydxWNxFNZ/a5VgIrVfDqhfD6xvyeGB6xWzeYfwqXqUggjEYhbIcMXXDUEINgIIwAAwCrCSIji6AXAduALzmfwHqtV6CGMAOhUvA94jzdN71Gr8EYYgYdQPrEt1HAuhfe4AyuA9hBGIgQfGgL/yamjw+Kh8EktBLogqeOvW0LhK4ZQeL28EgIdDYXXKxJ4W+Wu8GoQRgLA7898lj4shuen1AD/NDtHNazpypUP9KYVrE01FNb/cNkNcQl75yCMwEMIfOgC3Fgdvce26z1KFXoIIwDaFS6fYAGEL8JIF2X7U5Lt+Tfy5rtt210Nle/fvbmM1nZPQ6ZWIdIPoKsgjIQxX7735cMtAi0UzjsIF7YrZXv+jbzph+0jcbbn38iXc/tCpMunhTACAACsIoxEIO5qiXDBqoqgYMUKOYSREOLr9mFkIvYn1cPjO/tw6KP/Avka+PPeEIi5d9YrFMj5+DOtTqmVFzPxph/+5oRA1TgQOaWjaXhXh8javxNGuqj2vm5s77vIYP1kuVfjBGS+zX/+u+Op2v6+1a9zLwJw74MWP5XuxYsWzFp5dT6Blz2IauPfvmhaDm/Xq8463yCQ8/FcTj+n0Unj+COQ8+E8qeAhjMADRy8BAJ3NrzAyb948paWlKS4uTunp6crPz2+3/dy5c3XhhReqR48eSk1N1b333qsTJ0741WEAkYR07C3OBfMelQo9PoeRxYsXKzs7W7NmzdLGjRs1fPhwZWVlqby8vNX2r776qqZPn65Zs2Zpx44devHFF7V48WL9+te/Pu3OAwCA8OdzGJkzZ47uuOMOTZ48WRdffLHmz5+vnj17auHCha22/+ijj3TllVfqlltuUVpamq6//nrdfPPNHR5NAQAAkcGnMFJbW6uCggJlZmaemkB0tDIzM5WXl9fqOFdccYUKCgrc4aOoqEhLly7V9773vTbnU1NTI6fT6fGINBxGBABEim6+ND506JDq6+uVnJzsMTw5OVk7d+5sdZxbbrlFhw4d0lVXXSVjjOrq6nTnnXe2+zVNTk6OHnnkEV+6BgAAwlTQr6ZZtWqVnnjiCT377LPauHGj3nzzTS1ZskSPPvpom+PMmDFDlZWV7kdJSUmwu9nl2D6Xzdp9I5rNuK17YTQd7vd8A1Rjb+/X4bFs3t5/oFk74/HvZrUK4m/TeHVfBa/aeFkrH6fb2rQ9yu3letVZArl9ey6nf/MP5SO5gb3HSygvaXjz6chIUlKSYmJiVFZW5jG8rKxMKSkprY7z8MMP69Zbb9Xtt98uSRo2bJiqq6v185//XA8++KCio1vmIYfDIYfD4UvXrPL/2vzm93lo+pzv43dlzWscasseFWU/AHY2f1+DUPntDyn073URsPv+BGC6HY7ixTTD8bdp/LqHSlQH93PyahohtKF0Ap+OjMTGxmrUqFHKzc11D3O5XMrNzVVGRkar4xw7dqxF4IiJiZHEpWjoOliVvUetvEetvMf7SXjz6ciIJGVnZ2vSpEkaPXq0xowZo7lz56q6ulqTJ0+WJE2cOFEDBw5UTk6OJGncuHGaM2eORo4cqfT0dH322Wd6+OGHNW7cOHcoQediow2QyPrgclooFYD2+BxGxo8fr4qKCs2cOVOlpaUaMWKEli1b5j6ptbi42ONIyEMPPaSoqCg99NBDOnDggM466yyNGzdOjz/+eOCWAkCXRG72HrXyHrUKPT6HEUm6++67dffdd7f63KpVqzxn0K2bZs2apVmzZvkzKwAA0MXx2zQAAMAqwkgI8fXQofn6P++m3XWOSxrj/XJ7jhfojnTy/MJYqJYiVPvVHlvrVYez9aJf4Vhvf3T0Gnl1GbsP+7musK8hjAQEp+cFQiCq6O1PvQdap1+FF4Cfem95abndWgVr7oG4rNbb9SrQ61ubtTrN2QS61v5d/tpJ69vpjh9hl9jaQhgBELK6wAe+TkOtvMfNy0IPYQTNsJECADoXYaTLsny7aqtzP8WrT0BheOv8YGjrvKKmh6lt99X2/BvxyRoILMJIGPPl+2m+9wyuUHmT7Ez+rlKRWSv/ihWoWoXK9h/M28EHarUKjUr59pqFyMt7WggjaKYLrNWdhVJ5zd9SRWJw8Re18h61Cj1RJgyu+XQ6nUpISFBlZaXi4+MDNt26epfOe/C9Np/v5eimozV1rT435dpztbvsqFZsL2v1eV/ddtVgvbh2b0CmdbrOSTpDBytP6PjJ+oBM77oh/TQiNVFPr9gdkOndftVgvRAitRp+doI2f14ZsOn16+3QjO8N0b2LN/s9jTFpfZW/77Ak6ZIBDdvLti+cAenf6RiRmqgtBypV7wrcLmfhT0frZy9v8Hv8ay48S6t2Vbj/vuLcM/XRni87HC+ue7ROnHT5Pd+ODEnprQNHjqvqROv7H3/M/49RuvOvBX6P7+gWrZq6U8ucdUmylm/reP93TtIZKjpU7fd8O3LuWWfoq2MnVXn8ZMDWrf/+0TDNeHOLArWq3jxmkF7LLw7MxE5D3zNiFR0VpZq6+lbXrX2zxwZ8nt6+f0d0GPnd8p2at3JPwKYHAEC42vpIlno5/Loxe5u8ff+O6K9p1n56yHYXAAAICcdrA3M03B8RHUYAAIB9hBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWRHUa6wm3rAAAIc5EdRgAAgCS7v7kU0WGE4yIAANgX0WEEAADYRxgBAABWEUYAAICiLJ68ENFhhItpAACwL6LDCAAAsI8wAgAAuLTXFr6lAQDAvogOIwAAwD7CCAAAsCqiw0gUl9MAAGBdRIcRAABgH2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWBXRYYSbwQMAYF9EhxEAAPA1Y2/WER1G+J08AADsi+gwAgAA7COMAAAAqwgjAADA6lUdER1GorieBgAA6yI6jAAAAPsIIwAAgEt7reFbGgAArIvsMAIAAKwjjAAAAKsiOozwLQ0AAPZFdBgBAAD2EUYAAIBVhBEAAGBVRIcRi5dUAwCAr/kVRubNm6e0tDTFxcUpPT1d+fn57bY/cuSIpkyZov79+8vhcOiCCy7Q0qVL/eowAADoWrr5OsLixYuVnZ2t+fPnKz09XXPnzlVWVpZ27dqlfv36tWhfW1ur7373u+rXr5/+9re/aeDAgdq/f78SExMD0f/TwtU0AADY53MYmTNnju644w5NnjxZkjR//nwtWbJECxcu1PTp01u0X7hwoQ4fPqyPPvpI3bt3lySlpaWdXq8BAECX4dPXNLW1tSooKFBmZuapCURHKzMzU3l5ea2O88477ygjI0NTpkxRcnKyhg4dqieeeEL19fVtzqempkZOp9PjAQAAuiafwsihQ4dUX1+v5ORkj+HJyckqLS1tdZyioiL97W9/U319vZYuXaqHH35YTz/9tB577LE255OTk6OEhAT3IzU11ZduAgCAMBL0q2lcLpf69eun559/XqNGjdL48eP14IMPav78+W2OM2PGDFVWVrofJSUlwe4mAACwxKdzRpKSkhQTE6OysjKP4WVlZUpJSWl1nP79+6t79+6KiYlxD7voootUWlqq2tpaxcbGthjH4XDI4XD40jW/RHEGKwAAkuze7sKnIyOxsbEaNWqUcnNz3cNcLpdyc3OVkZHR6jhXXnmlPvvsM7lcLvew3bt3q3///q0Gkc4UxfU0AABY5/PXNNnZ2VqwYIH+9Kc/aceOHbrrrrtUXV3tvrpm4sSJmjFjhrv9XXfdpcOHD2vq1KnavXu3lixZoieeeEJTpkwJ3FIAAICw5fOlvePHj1dFRYVmzpyp0tJSjRgxQsuWLXOf1FpcXKzo6FMZJzU1VcuXL9e9996rSy+9VAMHDtTUqVP1wAMPBG4pAABA2IoyxoT8XdGdTqcSEhJUWVmp+Pj4gE335ufXKa/oy4BNDwCAcLX+19cpOT4uoNP09v07on+bBgAANLB5FiVhBAAAWBXRYYRLewEAsC+iwwgAAGgQNvcZ6Wo4MgIAgH0RHUYAAIB9hBEAAGBVRIcRbgcPAIB9ER1GAACAfYQRAABgFWEEAABYFdFhxFi9qhoAAEgRHkYAAIB9ER1GuJoGAAD7IjqMAAAA+wgjAADAKsIIAACwijACAACsiugwwq/2AgDQwFi820VEhxEAAGAfYQQAAFgV0WFkT/lR210AACDiRXQY+aLyhO0uAAAQ8SI6jAAAgAY2L+ogjAAAAKsIIwAAwCrCCAAA4D4jAAAgchFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAAAgI2Nt3oQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAKAoRVmbN2EEAABYRRgBAABWEUYAAAD3GQEAAJGLMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArPIrjMybN09paWmKi4tTenq68vPzvRpv0aJFioqK0k033eTPbAEAQBfkcxhZvHixsrOzNWvWLG3cuFHDhw9XVlaWysvL2x1v3759+tWvfqWrr77a784CAICux+cwMmfOHN1xxx2aPHmyLr74Ys2fP189e/bUwoUL2xynvr5eEyZM0COPPKJzzjnntDoMAAC6Fp/CSG1trQoKCpSZmXlqAtHRyszMVF5eXpvj/fa3v1W/fv102223eTWfmpoaOZ1OjwcAAOiafAojhw4dUn19vZKTkz2GJycnq7S0tNVx1q5dqxdffFELFizwej45OTlKSEhwP1JTU33pJgAACCNBvZqmqqpKt956qxYsWKCkpCSvx5sxY4YqKyvdj5KSkiD2EgAA2NTNl8ZJSUmKiYlRWVmZx/CysjKlpKS0aL9nzx7t27dP48aNcw9zuVwNM+7WTbt27dK5557bYjyHwyGHw+FL1wAAQJjy6chIbGysRo0apdzcXPcwl8ul3NxcZWRktGg/ZMgQbdmyRYWFhe7H97//fV177bUqLCzk6xcAAODbkRFJys7O1qRJkzR69GiNGTNGc+fOVXV1tSZPnixJmjhxogYOHKicnBzFxcVp6NChHuMnJiZKUovhAADAHmPszdvnMDJ+/HhVVFRo5syZKi0t1YgRI7Rs2TL3Sa3FxcWKjubGrgAAwDtRxtjMQt5xOp1KSEhQZWWl4uPjAzbdtOlLAjYtAADC2UfTv6MBiT0COk1v3785hAEAAKwijAAAAKsIIwAAQFFR9uZNGAEAAFYRRgAAgFWEEQAAYPU+I4QRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAALL5q7mEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAICMsXenEcIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAQBZvM0IYAQAAdhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAAAgY+zNmzACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAkJG9G40QRgAAgFWEEQAAYBVhBAAAWEUYAQAAVvkVRubNm6e0tDTFxcUpPT1d+fn5bbZdsGCBrr76avXp00d9+vRRZmZmu+0BAEBk8TmMLF68WNnZ2Zo1a5Y2btyo4cOHKysrS+Xl5a22X7VqlW6++WatXLlSeXl5Sk1N1fXXX68DBw6cducBAED4izLGtx8NTk9P1+WXX65nnnlGkuRyuZSamqp77rlH06dP73D8+vp69enTR88884wmTpzo1TydTqcSEhJUWVmp+Ph4X7rbrrTpSwI2LQAAwtmqX12jtKQzAjpNb9+/fToyUltbq4KCAmVmZp6aQHS0MjMzlZeX59U0jh07ppMnT6pv375ttqmpqZHT6fR4AACArsmnMHLo0CHV19crOTnZY3hycrJKS0u9msYDDzygAQMGeASa5nJycpSQkOB+pKam+tJNAAAQRjr1aprZs2dr0aJFeuuttxQXF9dmuxkzZqiystL9KCkp6cReAgCAztTNl8ZJSUmKiYlRWVmZx/CysjKlpKS0O+5TTz2l2bNn65///KcuvfTSdts6HA45HA5fugYAAMKUT0dGYmNjNWrUKOXm5rqHuVwu5ebmKiMjo83xnnzyST366KNatmyZRo8e7X9vAQBAl+PTkRFJys7O1qRJkzR69GiNGTNGc+fOVXV1tSZPnixJmjhxogYOHKicnBxJ0n//939r5syZevXVV5WWluY+t6RXr17q1atXABcFAACEI5/DyPjx41VRUaGZM2eqtLRUI0aM0LJly9wntRYXFys6+tQBl+eee061tbX6t3/7N4/pzJo1S7/5zW9Or/cAACDs+XyfERu4zwgAAMG18lfXaHA43GcEAAAg0AgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAGTztmOEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAACyd2EvYQQAAFhGGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAAAgY/FGI4QRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAJLsXdtLGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAADI2LvNCGEEAADYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAIIu3GSGMAAAAuwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAAJCxeG0vYQQAAFhFGAEAAFYRRgAAgFV+hZF58+YpLS1NcXFxSk9PV35+frvt33jjDQ0ZMkRxcXEaNmyYli5d6ldnAQBA1+NzGFm8eLGys7M1a9Ysbdy4UcOHD1dWVpbKy8tbbf/RRx/p5ptv1m233aZNmzbppptu0k033aStW7eeducBAED4izLGt/Nn09PTdfnll+uZZ56RJLlcLqWmpuqee+7R9OnTW7QfP368qqur9e6777qHffOb39SIESM0f/58r+bpdDqVkJCgyspKxcfH+9LddqVNXxKwaQEAEM6WT/uWLkzpHdBpevv+7dORkdraWhUUFCgzM/PUBKKjlZmZqby8vFbHycvL82gvSVlZWW22l6Samho5nU6PBwAACJ7Pvzpmbd4+hZFDhw6pvr5eycnJHsOTk5NVWlra6jilpaU+tZeknJwcJSQkuB+pqam+dBMAAPgoOirK3rytzbkdM2bMUGVlpftRUlISlPn88rsXtPncZYMSgzLPQBg6sOOvqqKjpOR4h7pFt75yJfToLkm64twzPcZpS98zYtt87l8u7d9hf2wZ4uUhx4GJPdpcxoGJPSRJ6YP7Kq57x5tM2pk923wu86J+XvXHhtS+Pbxql3ZmTyX1ar1W/RPiJEnn9eulpF6ODqf1jXZqNTw10av+2ODNeiBJFyT3cm9rzcV2i3b//5ykM9zDe8bGtNq+vW0wrnt0m+OFi/P69Wp3GRsNG5jg/nfj+uYrb/cLNpzpRQ0GJvbwavu6PK2P+9/t1WpQ354ak9ZXF1isSzdfGiclJSkmJkZlZWUew8vKypSSktLqOCkpKT61lySHwyGHo+NCn657rjtf91x3ftDnEwmeucV2DwAA4cqnIyOxsbEaNWqUcnNz3cNcLpdyc3OVkZHR6jgZGRke7SVpxYoVbbYHAACRxacjI5KUnZ2tSZMmafTo0RozZozmzp2r6upqTZ48WZI0ceJEDRw4UDk5OZKkqVOn6tvf/raefvppjR07VosWLdKGDRv0/PPPB3ZJAABAWPI5jIwfP14VFRWaOXOmSktLNWLECC1btsx9kmpxcbGio08dcLniiiv06quv6qGHHtKvf/1rnX/++Xr77bc1dOjQwC0FAAAIWz7fZ8SGYN1nBAAABE9Q7jMCAAAQaIQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFU+3w7ehsabxDqdTss9AQAA3mp83+7oZu9hEUaqqqokSampqZZ7AgAAfFVVVaWEhIQ2nw+L36ZxuVz64osv1Lt3b0VFRQVsuk6nU6mpqSopKeE3bwKIugYHdQ0O6hp41DQ4wrGuxhhVVVVpwIABHj+i21xYHBmJjo7W2WefHbTpx8fHh80LG06oa3BQ1+CgroFHTYMj3Ora3hGRRpzACgAArCKMAAAAqyI6jDgcDs2aNUsOh8N2V7oU6hoc1DU4qGvgUdPg6Mp1DYsTWAEAQNcV0UdGAACAfYQRAABgFWEEAABYRRgBAABWRXQYmTdvntLS0hQXF6f09HTl5+fb7lLIyMnJ0eWXX67evXurX79+uummm7Rr1y6PNidOnNCUKVN05plnqlevXvrRj36ksrIyjzbFxcUaO3asevbsqX79+um+++5TXV2dR5tVq1bpsssuk8Ph0HnnnaeXX3452IsXEmbPnq2oqChNmzbNPYya+ufAgQP6j//4D5155pnq0aOHhg0bpg0bNrifN8Zo5syZ6t+/v3r06KHMzEx9+umnHtM4fPiwJkyYoPj4eCUmJuq2227T0aNHPdp88sknuvrqqxUXF6fU1FQ9+eSTnbJ8NtTX1+vhhx/W4MGD1aNHD5177rl69NFHPX5jhLp2bM2aNRo3bpwGDBigqKgovf322x7Pd2YN33jjDQ0ZMkRxcXEaNmyYli5dGvDl9ZuJUIsWLTKxsbFm4cKFZtu2beaOO+4wiYmJpqyszHbXQkJWVpZ56aWXzNatW01hYaH53ve+ZwYNGmSOHj3qbnPnnXea1NRUk5ubazZs2GC++c1vmiuuuML9fF1dnRk6dKjJzMw0mzZtMkuXLjVJSUlmxowZ7jZFRUWmZ8+eJjs722zfvt384Q9/MDExMWbZsmWdurydLT8/36SlpZlLL73UTJ061T2cmvru8OHD5hvf+Ib56U9/atavX2+KiorM8uXLzWeffeZuM3v2bJOQkGDefvtts3nzZvP973/fDB482Bw/ftzd5oYbbjDDhw8369atMx988IE577zzzM033+x+vrKy0iQnJ5sJEyaYrVu3mtdee8306NHD/PGPf+zU5e0sjz/+uDnzzDPNu+++a/bu3WveeOMN06tXL/P73//e3Ya6dmzp0qXmwQcfNG+++aaRZN566y2P5zurhh9++KGJiYkxTz75pNm+fbt56KGHTPfu3c2WLVuCXgNvRGwYGTNmjJkyZYr77/r6ejNgwACTk5NjsVehq7y83Egyq1evNsYYc+TIEdO9e3fzxhtvuNvs2LHDSDJ5eXnGmIaNMDo62pSWlrrbPPfccyY+Pt7U1NQYY4y5//77zSWXXOIxr/Hjx5usrKxgL5I1VVVV5vzzzzcrVqww3/72t91hhJr654EHHjBXXXVVm8+7XC6TkpJifve737mHHTlyxDgcDvPaa68ZY4zZvn27kWQ+/vhjd5v33nvPREVFmQMHDhhjjHn22WdNnz593HVunPeFF14Y6EUKCWPHjjU/+9nPPIb98Ic/NBMmTDDGUFd/NA8jnVnDH//4x2bs2LEe/UlPTzf/+Z//GdBl9FdEfk1TW1urgoICZWZmuodFR0crMzNTeXl5FnsWuiorKyVJffv2lSQVFBTo5MmTHjUcMmSIBg0a5K5hXl6ehg0bpuTkZHebrKwsOZ1Obdu2zd2m6TQa23Tl12HKlCkaO3Zsi+Wmpv555513NHr0aP37v/+7+vXrp5EjR2rBggXu5/fu3avS0lKPmiQkJCg9Pd2jromJiRo9erS7TWZmpqKjo7V+/Xp3m29961uKjY11t8nKytKuXbv01VdfBXsxO90VV1yh3Nxc7d69W5K0efNmrV27VjfeeKMk6hoInVnDUN8vRGQYOXTokOrr6z126JKUnJys0tJSS70KXS6XS9OmTdOVV16poUOHSpJKS0sVGxurxMREj7ZNa1haWtpqjRufa6+N0+nU8ePHg7E4Vi1atEgbN25UTk5Oi+eoqX+Kior03HPP6fzzz9fy5ct111136b/+67/0pz/9SdKpurS3vZeWlqpfv34ez3fr1k19+/b1qfZdyfTp0/WTn/xEQ4YMUffu3TVy5EhNmzZNEyZMkERdA6Eza9hWm1CpcVj8ai/smjJlirZu3aq1a9fa7kpYKykp0dSpU7VixQrFxcXZ7k6X4XK5NHr0aD3xxBOSpJEjR2rr1q2aP3++Jk2aZLl34ev111/XK6+8oldffVWXXHKJCgsLNW3aNA0YMIC6IuAi8shIUlKSYmJiWlylUFZWppSUFEu9Ck1333233n33Xa1cuVJnn322e3hKSopqa2t15MgRj/ZNa5iSktJqjRufa69NfHy8evToEejFsaqgoEDl5eW67LLL1K1bN3Xr1k2rV6/W//7v/6pbt25KTk6mpn7o37+/Lr74Yo9hF110kYqLiyWdqkt723tKSorKy8s9nq+rq9Phw4d9qn1Xct9997mPjgwbNky33nqr7r33XvdRPep6+jqzhm21CZUaR2QYiY2N1ahRo5Sbm+se5nK5lJubq4yMDIs9Cx3GGN19991666239P7772vw4MEez48aNUrdu3f3qOGuXbtUXFzsrmFGRoa2bNnisSGtWLFC8fHx7jePjIwMj2k0tumKr8N1112nLVu2qLCw0P0YPXq0JkyY4P43NfXdlVde2eKy8927d+sb3/iGJGnw4MFKSUnxqInT6dT69es96nrkyBEVFBS427z//vtyuVxKT093t1mzZo1OnjzpbrNixQpdeOGF6tOnT9CWz5Zjx44pOtrzLSImJkYul0sSdQ2EzqxhyO8XbJ9Ba8uiRYuMw+EwL7/8stm+fbv5+c9/bhITEz2uUohkd911l0lISDCrVq0yBw8edD+OHTvmbnPnnXeaQYMGmffff99s2LDBZGRkmIyMDPfzjZehXn/99aawsNAsW7bMnHXWWa1ehnrfffeZHTt2mHnz5nXpy1Cba3o1jTHU1B/5+fmmW7du5vHHHzeffvqpeeWVV0zPnj3NX//6V3eb2bNnm8TERPP3v//dfPLJJ+Zf//VfW718cuTIkWb9+vVm7dq15vzzz/e4fPLIkSMmOTnZ3HrrrWbr1q1m0aJFpmfPnl3mEtTmJk2aZAYOHOi+tPfNN980SUlJ5v7773e3oa4dq6qqMps2bTKbNm0yksycOXPMpk2bzP79+40xnVfDDz/80HTr1s089dRTZseOHWbWrFlc2hsq/vCHP5hBgwaZ2NhYM2bMGLNu3TrbXQoZklp9vPTSS+42x48fN7/4xS9Mnz59TM+ePc0PfvADc/DgQY/p7Nu3z9x4442mR48eJikpyfzyl780J0+e9GizcuVKM2LECBMbG2vOOeccj3l0dc3DCDX1zz/+8Q8zdOhQ43A4zJAhQ8zzzz/v8bzL5TIPP/ywSU5ONg6Hw1x33XVm165dHm2+/PJLc/PNN5tevXqZ+Ph4M3nyZFNVVeXRZvPmzeaqq64yDofDDBw40MyePTvoy2aL0+k0U6dONYMGDTJxcXHmnHPOMQ8++KDH5aPUtWMrV65sdV86adIkY0zn1vD11183F1xwgYmNjTWXXHKJWbJkSdCW21dRxjS5nR4AAEAni8hzRgAAQOggjAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALDq/wMLzAb4ViVwuwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(2).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9949])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/best.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jheli\\Downloads\\TR\\building_model.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jheli/Downloads/TR/building_model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### Testing models with test data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jheli/Downloads/TR/building_model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#################################\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jheli/Downloads/TR/building_model.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m net_loaded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./models/best.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jheli/Downloads/TR/building_model.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m total_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jheli/Downloads/TR/building_model.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(test_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/best.pkl'"
     ]
    }
   ],
   "source": [
    "### Testing models with test data\n",
    "#################################\n",
    "\n",
    "net_loaded = torch.load('./models/best.pkl')\n",
    "total_correct = 0\n",
    "total = len(test_data)\n",
    "for specs, labels in test_loader:\n",
    "    # feeding the model\n",
    "    predictions = net_loaded(specs)\n",
    "    # computing accuracy\n",
    "    total_correct += sum(torch.abs(predictions-labels) <= 0.5)\n",
    "# printing accuracy\n",
    "print(total_correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
